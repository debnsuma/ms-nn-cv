{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcOYvbDOrs6Z"
   },
   "source": [
    "## Recap of Last Lecture:\n",
    "\n",
    "- In the last class we began by introducing the field of **Computer Vision**, it's wide-ranging applications and reflecting on why it's hard!\n",
    "- We then saw how adding CNN Blocks inplace of MLPs improved overall performance of our model on an image dataset. \n",
    "- After that, we delved into the intuition behind CNNs, it's various components and how each of them worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8ON6WyLIgB-"
   },
   "source": [
    "## Agenda for this Lecture:\n",
    "\n",
    "- This lecture is divided into two parts: In Part 1,  we will **code a Convolution Block from scratch** and in Part 2, we will see ways to deal with the **Issue of Overfitting** in CNNs.\n",
    "- Part 1 will be focussed on understanding the working of **Convolution** and **Pooling** functions by implementing it from scratch.\n",
    "- In Part 2 we will broadly cover two classes of regularization techniques, \n",
    "    1. Modifications in **Model Pipeline** (architecture, loss functions etc.) \n",
    "    2. Modifications in **Data Pipeline** (data augmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NlGb-DlFZCFC"
   },
   "source": [
    "# Part 1. Convolution Block From Scratch\n",
    "\n",
    "In this segment, we will extend our understanding about Convolution and MaxPooling by implementing them from scratch (using Numpy). Using some predefined filters, we will then apply convolution operation on a sample image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05Uo5L1L6kEQ"
   },
   "source": [
    "### Setup (Import Statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtvQ4Hnp6iGs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import rescale, resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAwMPDM9YJ4X"
   },
   "source": [
    "### 1. Implementation of Conv Block (Convolution + Non-Linearity + Pooling) using Numpy\n",
    "\n",
    "- Convolution:\n",
    "    - In this function, we take in an image and a kernel (2D matrix), along with two optional parameters; padding and strides (both integers) and return the convolved image.\n",
    "    - We iterate through every pixel in the image, and taking it as the central pixel, we perform element-wise multiplication of the surrounding pixels with the kernel pixels; finally replacing it with the net sum of those values.\n",
    "\n",
    "- Non-Linearity:\n",
    "    - We use ReLU as our non-linear function and apply it to every pixel in the image.\n",
    "    - Notice that here we use a vectorized and more efficient implementation.\n",
    "- Pooling:\n",
    "    - We implement MaxPooling, in much the same way as Convolution, except that this time, we don't apply kernel over the image, rather a max function over a region of image surrounding the central pixel. That region is determined by the `size` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZPdef1yY1hQ"
   },
   "outputs": [],
   "source": [
    "# Convolution function\n",
    "def convolve2D(image, kernel, padding, strides):\n",
    "    # Gather Shapes of Kernel + Image + Padding\n",
    "    (xImgShape, yImgShape) = image.shape[: 2]\n",
    "    (xKernShape, yKernShape) = kernel.shape[: 2]\n",
    "\n",
    "    # Shape of Output Convolution\n",
    "    xOutput = int(((xImgShape - xKernShape + 2 * padding) / strides) + 1)\n",
    "    yOutput = int(((yImgShape - yKernShape + 2 * padding) / strides) + 1)\n",
    "    output = np.zeros((xOutput, yOutput))\n",
    "  \n",
    "    # Apply Equal Padding to All Sides\n",
    "    if padding != 0:\n",
    "        imagePadded = np.zeros((image.shape[0] + padding * 2, image.shape[1] + padding * 2))\n",
    "        imagePadded[int(padding):int(-1 * padding), int(padding) : int(-1 * padding)] = image\n",
    "        # print(imagePadded)\n",
    "    else:\n",
    "        imagePadded = image\n",
    "\n",
    "    # Iterate through image\n",
    "    for y in np.arange(0, image.shape[1], strides):\n",
    "        # Exit Convolution\n",
    "        if y > image.shape[1] - yKernShape:\n",
    "            break\n",
    "        # Only Convolve if y has gone down by the specified Strides\n",
    "        if y % strides == 0:\n",
    "            for x in range(0, image.shape[0], strides):\n",
    "                # Go to next row once kernel is out of bounds\n",
    "                if x > image.shape[0] - xKernShape:\n",
    "                    break\n",
    "                try:\n",
    "                    # Only Convolve if x has moved by the specified Strides\n",
    "                    if x % strides == 0:\n",
    "                        output[x, y] = (kernel * imagePadded[x : x + xKernShape, y : y + yKernShape]).sum()\n",
    "                except:\n",
    "                    break\n",
    "\n",
    "    return output\n",
    "\n",
    "# Non-linearity (ReLU) function\n",
    "def relu(feature_map):\n",
    "    relu_out = np.where(feature_map > 0, feature_map, 0)\n",
    "    return relu_out\n",
    "\n",
    "# Pooling (MaxPool) function\n",
    "def pooling(feature_map, size, stride):\n",
    "    # Shape of pooling\n",
    "    xOutput = int(((feature_map.shape[0] - size) / stride) + 1)\n",
    "    yOutput = int(((feature_map.shape[1] - size) / stride) + 1)\n",
    "    pool_output = np.zeros((xOutput, yOutput))\n",
    "\n",
    "    # Iterate through image\n",
    "    x2 = 0\n",
    "    for y in np.arange(0,feature_map.shape[1],stride):\n",
    "        # Exit Convolution\n",
    "        if y > feature_map.shape[1] - size:\n",
    "            break\n",
    "        y2 = 0\n",
    "        # Only Convolve if y has gone down by the specified Strides\n",
    "        if y % stride == 0:\n",
    "          for x in np.arange(0, feature_map.shape[0], stride):\n",
    "              # Go to next row once kernel is out of bounds\n",
    "              if x > feature_map.shape[0] - size:\n",
    "                  break\n",
    "              try:\n",
    "                  # Only Convolve if x has moved by the specified Strides\n",
    "                  if x % stride == 0:\n",
    "                      pool_output[x2, y2] =  np.max([feature_map[y : y+size,  x : x+size]])\n",
    "                      y2 += 1\n",
    "              except:\n",
    "                  break\n",
    "          x2 += 1\n",
    "\n",
    "    return pool_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xt3my7QMYbC-"
   },
   "source": [
    "### 2. Common Filters\n",
    "- In Lecture 1, we had already looked at some of the common filters, namely Horizontal and Vertical Filter.  \n",
    "    - **Horizontal Filter** -\n",
    "        \\begin{bmatrix}\n",
    "        1&   0&  -1\\\\ \n",
    "        1&   0&  -1\\\\ \n",
    "        1&   0&  -1\n",
    "        \\end{bmatrix}\n",
    "    - **Vertical Filter** -\n",
    "        \\begin{bmatrix}\n",
    "        1&  1&  1\\\\ \n",
    "        0&  0&  0\\\\ \n",
    "        -1&  -1&  -1\n",
    "        \\end{bmatrix}\n",
    "\n",
    "- In this lecture, we will introduce two new filters and operate with it; namely,\n",
    "    1. **Sharpen Filter** - As the name suggests, it is used to enhance the edges of objects and adjust the contrast and the shade characteristics in a image, with a matrix like the one shown below:\n",
    "<br>\n",
    "\\begin{bmatrix}\n",
    "0&  -1&  0\\\\ \n",
    "-1&  5& -1\\\\ \n",
    "0&  -1& 0\n",
    "\\end{bmatrix}\n",
    "    2. **Blur Filter** - It has the effect of smoothening of image, by averaging all pixels surrounding a central pixel and replacing it with the averaged value. A 3x3 average filter is shown below:\n",
    "    <br>\n",
    "\\begin{bmatrix}\n",
    "\\frac{1}{9}&  \\frac{1}{9}&  \\frac{1}{9}\\\\ \n",
    "\\frac{1}{9}&  \\frac{1}{9}&  \\frac{1}{9}\\\\ \n",
    "\\frac{1}{9}&  \\frac{1}{9}&  \\frac{1}{9}\n",
    "\\end{bmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utpE3cMWYacU"
   },
   "outputs": [],
   "source": [
    "# construct average blurring kernels used to smooth an image\n",
    "blur_filter = np.ones((3, 3), dtype='float') * (1.0 / (3 * 3))\n",
    "\n",
    "\n",
    "# construct a sharpening filter\n",
    "sharpen_filter = np.array((\n",
    "     [0, -1,  0],\n",
    "     [-1, 5, -1],\n",
    "     [0, -1,  0]), dtype='int')\n",
    "\n",
    "kernelBank = [(\"blur\",blur_filter), (\"sharpen\",sharpen_filter)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMKZHKyVY1SN"
   },
   "source": [
    "### 3. Apply Conv Block on a Sample Image using above Filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "GqmNYcVGZAFc",
    "outputId": "bb4f5639-58f9-4868-d7d5-a7ca67c31cf3"
   },
   "outputs": [],
   "source": [
    "img = skimage.data.chelsea()\n",
    "# Converting the image into gray.\n",
    "gray = skimage.color.rgb2gray(img)\n",
    "gray = resize(gray, (252, 252))\n",
    "\n",
    "for (kernelName, K) in kernelBank:\n",
    "    print(\"[INFO] applying {} kernel\".format(kernelName))\n",
    "    output = convolve2D(gray, K, 0, 1)\n",
    "    act = relu(output)\n",
    "    pool = pooling(act, size=2, stride=2)\n",
    "\n",
    "    f, axarr = plt.subplots(1, 4, figsize=(12, 12))\n",
    "    axarr[0].imshow(gray, cmap='gray')\n",
    "    axarr[1].imshow(output, cmap='gray')\n",
    "    axarr[2].imshow(act, cmap='gray')\n",
    "    axarr[3].imshow(pool, cmap='gray')\n",
    "\n",
    "    axarr = axarr.ravel()\n",
    "    axarr[0].set_title(\"Original image\")\n",
    "    axarr[1].set_title(kernelName)\n",
    "    axarr[2].set_title(\"relu\")\n",
    "    axarr[3].set_title(\"pooling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZkepWpcZVAO"
   },
   "source": [
    "- In the above example, we saw how different functions in Conv-Block operate on an Image and what visual changes they create.\n",
    "- In other words, we showed how Forward Propagation actually works in a Conv-Block with the help of predefined filters.\n",
    "- In the next lecture, we will implement both forward and backward propagation from scratch and train it on a custom dataset.  \n",
    "\n",
    "But for now, let's move on to the next Part, which is about dealing with Overfitting in CNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KrwttDzK8Cp"
   },
   "source": [
    "#Part 2. Tackling Overfitting\n",
    "\n",
    "There are broadly two ways in which we can reduce overfitting -\n",
    "\n",
    "- #### ***1. Modifications in Model Pipeline:***  Improving ***Network*** Configuration to solve over-parametrization\n",
    "- #### ***2. Modifications in Data Pipeline:***  Augmenting ***Dataset*** to increase the number of samples\n",
    "\n",
    "**But before even talking about these techniques, let's revisit the problem statement and the baseline model we developed in the last lecture** - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcuDw2jEB6_q"
   },
   "source": [
    "### Setup \n",
    "\n",
    "#### Download Data\n",
    "\n",
    "We are going to use the same collection of real-world clothing images dataset as in the first lecture, opensourced [here](https://github.com/alexeygrigorev/clothing-dataset-small).  \n",
    "\n",
    "You can read more about the dataset in this [blog post](https://medium.com/data-science-insider/clothing-dataset-5b72cd7c3f1f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaycWEp8B7sN",
    "outputId": "187ce446-6c65-4b22-a18b-e636f01f27d5"
   },
   "outputs": [],
   "source": [
    "# !gdown https://drive.google.com/uc?id=1XdXz0TKo_KCDRHOMvzV-YtcTx7NPG-jC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M_3HAeiNB_jF",
    "outputId": "3859ce88-c091-4268-ccb6-40b0c4171376"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/clothing-dataset-small.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBKbQxnLydG_"
   },
   "source": [
    "#### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEH97rTJydG_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(111)\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKZaBhntydHB"
   },
   "source": [
    "## 0. Revisiting CNNs\n",
    "\n",
    "Let's start from where we left off- \n",
    "\n",
    "[A typical CNN training pipeline]\n",
    "\n",
    "- Problem Type: Image Classification\n",
    "- Dataset: Clothing Dataset, 10 classes\n",
    "- Model: 2-block (Conv+Maxpool) CNN model\n",
    "    - Performance: ~50% accuracy on test dataset\n",
    "\n",
    "These results are better than MLPs but far from perfect.   \n",
    "In this module, we will investigate the reasons for poor performance and seek solution to improve the accuracy of our model.\n",
    "\n",
    "Let's start with this as our **Baseline Model** and iteratively improve upon it to build a highly performant system. \n",
    "\n",
    "[Poll] Random Guess how much improvement we will be able to make (in terms of test accuracy) and in how many iterations (number of modifications)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa9RuSjWydHB"
   },
   "source": [
    "### Baseline Model\n",
    "\n",
    "This is the same CNN model which we used in the previous module to train our clothing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSP6Hl2kydHB"
   },
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_dir = \"/Users/debnsuma/Downloads/clothing-dataset-small\"):\n",
    "\n",
    "    assert os.path.exists(f\"{base_dir}/train\") and os.path.exists(f\"{base_dir}/validation\") and os.path.exists(f\"{base_dir}/test\")\n",
    "\n",
    "    print(\"Loading Data...\")\n",
    "    train_data_path = os.path.join(base_dir, \"train\")\n",
    "    train_data = tf.keras.utils.image_dataset_from_directory(train_data_path, shuffle=True, label_mode='categorical')\n",
    "\n",
    "    val_data_path = os.path.join(base_dir, \"validation\")\n",
    "    val_data = tf.keras.utils.image_dataset_from_directory(val_data_path, shuffle=False, label_mode='categorical')\n",
    "\n",
    "    test_data_path = os.path.join(base_dir, \"test\")\n",
    "    test_data = tf.keras.utils.image_dataset_from_directory(test_data_path, shuffle=False, label_mode='categorical')\n",
    "\n",
    "    return train_data, val_data, test_data, train_data.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data, class_names = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = len(train_data.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eoNgji3zydHB"
   },
   "source": [
    "#### Data Preprocessing: Resizing, Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDSwGLWHydHB"
   },
   "outputs": [],
   "source": [
    "def preprocess(train_data, val_data, test_data, target_height=128, target_width=128):\n",
    "\n",
    "    # Data Processing Stage with resizing and rescaling operations\n",
    "    data_preprocess = keras.Sequential(\n",
    "        name=\"data_preprocess\",\n",
    "        layers=[\n",
    "            layers.Resizing(target_height, target_width),\n",
    "            layers.Rescaling(1.0/255),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Perform Data Processing on the train, val, test dataset\n",
    "    train_ds = train_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    val_ds = val_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    test_ds = test_data.map(lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOp5iXTZydHB"
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = preprocess(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dpi255hGydHB"
   },
   "source": [
    "#### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5C8No24tydHB"
   },
   "outputs": [],
   "source": [
    "def baseline(height=128, width=128):\n",
    "    num_classes = 10\n",
    "    hidden_size = 256\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        name=\"model_cnn\",\n",
    "        layers=[\n",
    "            layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation='relu', input_shape=(height, width, 3)),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(units=hidden_size, activation='relu'),\n",
    "            layers.Dense(units=num_classes, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6l8mHE_OydHB",
    "outputId": "7d183b35-6856-445f-bcba-5a5a72f740a4"
   },
   "outputs": [],
   "source": [
    "model = baseline()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa3wXLhhydHC"
   },
   "source": [
    "#### Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def compile_train_v1(model, train_ds, val_ds, ckpt_path=\"checkpoint1.weights.h5\"):\n",
    "    epochs = 10\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model_fit = model.fit(train_ds, \n",
    "                          validation_data=val_ds, \n",
    "                          epochs=epochs, \n",
    "                          callbacks=[\n",
    "                              keras.callbacks.ModelCheckpoint(ckpt_path, \n",
    "                                                              save_weights_only=True, \n",
    "                                                              monitor='val_accuracy', \n",
    "                                                              mode='max', \n",
    "                                                              save_best_only=True),\n",
    "                          ])\n",
    "    return model_fit\n",
    "\n",
    "# Assuming model, train_ds, and val_ds are defined elsewhere in your code\n",
    "model_fit = compile_train_v1(model, train_ds, val_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5zimWk9ydHC"
   },
   "source": [
    "#### Plot Train and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRytp3yZydHC"
   },
   "outputs": [],
   "source": [
    "# helper function to annotate maximum values in the plots\n",
    "def annot_max(x,y, xytext=(0.94,0.96), ax=None, only_y=True):\n",
    "    xmax = x[np.argmax(y)]\n",
    "    ymax = max(y)\n",
    "    if only_y:\n",
    "        text = \"{:.2f}%\".format(ymax)\n",
    "    else:\n",
    "        text= \"x={:.2f}, y={:.2f}%\".format(xmax, ymax)\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "    bbox_props = dict(boxstyle=\"square,pad=0.3\", fc=\"w\", ec=\"k\", lw=0.72)\n",
    "    arrowprops=dict(arrowstyle=\"->\",connectionstyle=\"angle,angleA=0,angleB=60\")\n",
    "    kw = dict(xycoords='data',textcoords=\"axes fraction\",\n",
    "              arrowprops=arrowprops, bbox=bbox_props, ha=\"right\", va=\"top\")\n",
    "    ax.annotate(text, xy=(xmax, ymax), xytext=xytext, **kw)\n",
    "\n",
    "def plot_accuracy(model_fit):\n",
    "    #accuracy graph\n",
    "    x = range(0,len(model_fit.history['accuracy']))\n",
    "    y_train = [acc * 100 for acc in model_fit.history['accuracy']]\n",
    "    y_val = [acc * 100 for acc in model_fit.history['val_accuracy']]\n",
    "\n",
    "    plt.plot(x, y_train, label='Train', color='b')\n",
    "    annot_max(x, y_train, xytext=(0.7,0.9))\n",
    "    plt.plot(x, y_val, label='Val', color='r')\n",
    "    annot_max(x, y_val, xytext=(0.8,0.7))\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.xlabel('epoch', fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "UU7JU1cEydHC",
    "outputId": "be381c15-ab71-49d6-a8da-a672b7a27767"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMEdS96PydHC"
   },
   "source": [
    "#### Analyze Result on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVRSXQDGydHC"
   },
   "outputs": [],
   "source": [
    "def print_accuracy_stats(model, ds, class_names):\n",
    "    model.load_weights(\"checkpoint1.weights.h5\")\n",
    "    true_onehot = tf.concat([y for x, y in ds], axis=0)\n",
    "    true_categories = tf.argmax(true_onehot, axis=1)\n",
    "    y_pred = model.predict(ds)\n",
    "    predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "    test_acc = metrics.accuracy_score(true_categories, predicted_categories) * 100\n",
    "    print(f'\\nTest Accuracy: {test_acc:.2f}%\\n')\n",
    "\n",
    "# Note: This doesn't work with shuffled datasets\n",
    "def plot_confusion_matrix(model, ds, class_names):\n",
    "    model.load_weights(\"checkpoint1.weights.h5\")\n",
    "    true_onehot = tf.concat([y for x, y in ds], axis=0)\n",
    "    true_categories = tf.argmax(true_onehot, axis=1)\n",
    "    y_pred = model.predict(ds)\n",
    "    predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "    cm = metrics.confusion_matrix(true_categories,predicted_categories) # last batch \n",
    "    sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, cmap=\"YlGnBu\", fmt='g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "jfgS1ssZydHC",
    "outputId": "e42b7c1a-9958-4af7-a5a5-e77586cabcc3"
   },
   "outputs": [],
   "source": [
    "print_accuracy_stats(model, test_ds, class_names)\n",
    "plot_confusion_matrix(model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0vK_FgUydHC"
   },
   "source": [
    "#### What is the most apparent issue with the plots above?\n",
    "**Validation Accuracy very low as compared to Training Accuracy**\n",
    "(better known as Overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jabdLtygydHC"
   },
   "source": [
    "#### How do we solve the Overfitting in ML?\n",
    "\n",
    "Overfitting = More Trainable Parameters, Less Training Samples\n",
    "***Solutions -***\n",
    "1. More Data, Data Augmentation\n",
    "2. Reducing Complexity of Model Architecture (Smaller Model)\n",
    "3. Adding Regularizer to Model\n",
    "4. Adding Regularizer to Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oz4OcQJXydHC"
   },
   "source": [
    "## **1.** Modifications in Model Pipeline\n",
    "\n",
    "The baseline network has ~17 million parameters and just over 3000 images for training. This results in overparamterization of the network making it prone to overfit. One way to tackle this would be to remove some layers from the network. But since it's already a small network, that would badly affect the performance on both training/validation set (You can try yourself to see that!). So what else can we do?\n",
    "\n",
    "***HINT: Look at `model.summary()` carefully!***\n",
    "\n",
    "We find that over ~99% of the parameters are associated with just one layer, and that's not even the Convolutional layer. Although we introduced CNN in the model architecture, the number of trainable parameters as a result of that is just ~5000 which is 1000 times less than that of the Dense Layers in the architecture.\n",
    "\n",
    "The reason for it is that when we flatten the 3D matrix of shape 32x32x32 into 1D, the number of connections from that layer to dense layer explodes exponentially (no weight sharing in MLP).\n",
    "\n",
    "In order to avoid this, we will try do two things:\n",
    "1. Reduce the 3D volume before the flatten layer by using more Convolution blocks.\n",
    "2. Replace the flatten layer by `GlobalAveragePooling2D`  \n",
    "\n",
    "### **Modification #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arch_1(height=128, width=128):\n",
    "    num_classes = 10\n",
    "    hidden_size = 256\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation='relu', input_shape=(height, width, 3), name=\"conv2d_1\"),\n",
    "        layers.MaxPooling2D(name=\"maxpool2d_1\"),\n",
    "        layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation='relu', name=\"conv2d_2\"),\n",
    "        layers.MaxPooling2D(name=\"maxpool2d_2\"),\n",
    "        layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation='relu', name=\"conv2d_3\"),\n",
    "        layers.MaxPooling2D(name=\"maxpool2d_3\"),\n",
    "        layers.Conv2D(filters=128, kernel_size=3, padding=\"same\", activation='relu', name=\"conv2d_4\"),\n",
    "        layers.MaxPooling2D(name=\"maxpool2d_4\"),\n",
    "        layers.Conv2D(filters=256, kernel_size=3, padding=\"same\", activation='relu', name=\"conv2d_5\"),\n",
    "        layers.GlobalAveragePooling2D(name=\"global_avg_pool\"),\n",
    "        layers.Dense(units=hidden_size, activation='relu', name=\"dense_1\"),\n",
    "        layers.Dense(units=num_classes, activation='softmax', name=\"output\")\n",
    "    ], name=\"model_cnn\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qw7E5484ydHC",
    "outputId": "0c7468c4-b07b-46da-bec5-4f7e8cab108e"
   },
   "outputs": [],
   "source": [
    "model = arch_1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AL5j5L01ydHD"
   },
   "outputs": [],
   "source": [
    "def compile_train_v1(model, train_ds, val_ds, epochs=10, ckpt_path=\"checkpoint2.weights.h5\"):\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=[\n",
    "        keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "    ])\n",
    "    return model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PX_qc5gLydHD",
    "outputId": "55f05fe9-3c04-40dd-d3dd-f6d74e59f8b0"
   },
   "outputs": [],
   "source": [
    "model_fit = compile_train_v1(model, train_ds, val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "YZosPv5KydHD",
    "outputId": "aea791a5-404e-4c32-b573-1dd9a42fddc1"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwxS-UgYydHD"
   },
   "source": [
    "\n",
    "**Unbelievable!**  \n",
    "With just two modifications in the architecture, we can see the model performing much better and the problem of overfitting vanish.  \n",
    "\n",
    "This is good news, but something seems not right about the above plots!   \n",
    "#### **Can you guess what is wrong with the above plots?**  \n",
    "\n",
    "It seems the model was still improving when we stopped training leading to ***underfitting***!  \n",
    "So, let's continue training for more number of epochs. **But how many more epochs?**  \n",
    "\n",
    "The answer is that *we do not know*. But perhaps we can guess, by looking at the training plots. **Can you?**   \n",
    "\n",
    "- We can stop when the val loss/accuracy curve flattens out (or do not improve any further)!  \n",
    "- This technique is better known as \"early stopping\" and `keras` provides a readymade function for that. \n",
    "- Effectively, it stops model training, once the condition set by `EarlyStopping` is met.\n",
    "- Conditions could be based on either validation loss or accuracy numbers.\n",
    "- The `patience` argument determines that after how many \"epochs with no improvement\", training should be stopped.\n",
    "\n",
    "Let's plugin this into our training pipeline and see if it improves the result. [not implemented yet!]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QuWVfVklydHD",
    "outputId": "b9ce2930-4e2e-42fb-ef47-97c5ccec703b"
   },
   "outputs": [],
   "source": [
    "model_fit = compile_train_v1(model, train_ds, val_ds, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JxV-_O5MydHD",
    "outputId": "5f25a60e-45d1-466e-a65f-7027080cd149"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4klEXAOFydHD",
    "outputId": "32393eb9-0fcf-403e-e96d-1ab4f950f415"
   },
   "outputs": [],
   "source": [
    "print_accuracy_stats(model, test_ds, class_names)\n",
    "plot_confusion_matrix(model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BOlAYFXydHD"
   },
   "source": [
    "We see a **MASSIVE IMPROVEMENT** in the performance on test dataset, but is this the best number we can achieve, using architecture improvements?\n",
    "- Most Likely, the answer is No. Many improvements on the architecture side exists and we will look into some of them in subsequent lectures. (Also, heard of NAS?)\n",
    "- But before moving on, let's try one more thing in our model. We already know from previous lectures that adding Dropout and BatchNorm helps in regularizing the model, thus improving performance on validation dataset. (One question on BN, Dropout; does the introduce new \"training\" parameters?) Let's see it in action next.\n",
    "\n",
    "### **Modification #2** \n",
    "1. Add Batch Normalization after every `Conv2D` and `Dense` layers.\n",
    "2. Add `Dropout` after `Dense` layers\n",
    "\n",
    "#### **Q. What is Dropout and why is it required?**\n",
    "- Drops out random neurons from the network during training\n",
    "- Dropout reduces overfitting by :\n",
    "    - Reducing over - reliability of the network on using certain features to identify in a image\n",
    "    - Dropout thus encourages the network to utilize all the features to find pattern in a image\n",
    "    - Thus increasing overall generalization of our model, thus giving good model performance\n",
    "\n",
    "\n",
    "- Dropout is only used during training and not while evaluating our model as\n",
    "    - We want to use the capability of every learned neurons and really don't like to skip some of them randomly.\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1P0w9g-BuTHUCWQ6Xcz7A_lei_bQfdTX-' height=280></center>\n",
    "\n",
    "#### **Q. What is Batch Normalization?**\n",
    "- Simply put, it normalizes the inputs to each layer to a learnt representation likely close to μ = 0.0, σ = 1.0 wrt every minibatch.\n",
    "- It's a four-step process as described below:\n",
    "\n",
    "<center><img src='https://t3638486.p.clickup-attachments.com/t3638486/c04a328b-8726-4bce-9f8d-b121e0e157ba/image.png' height=200>\n",
    "<img src='https://drive.google.com/uc?id=12DwZw4uWID62jT6PJHlmzhKeEe9plhxe' height=300></center>\n",
    "\n",
    "#### **Q. Why Batch Normalization?**\n",
    "\n",
    "- In simple terms, just like input normalization, if all the layer inputs are normalized, then the significant outliers are less likely to impact the training process in a negative way. \n",
    "- And if they do, their impact will be much lower than without using Batch Normalization.\n",
    "- This inturn makes model less sensitive to hyperparameter tuning (for eg: larger LRs won't affect much the training process).\n",
    "\n",
    "#### **Q. How Batch Normalization Behaves during Inference?**\n",
    "\n",
    "- When inferring e.g. the class for a new sample, you wish to normalize it based on the entire training set, as it produces better estimates and is computationally feasible.\n",
    "\n",
    "- Hence, during inference, the Batch Normalization step goes as follows:\n",
    "<center><img src='https://t3638486.p.clickup-attachments.com/t3638486/e58670bb-997f-4acb-9909-534ec0536e1d/image.png' height=100></center>, where, 𝑥∈𝑋  and 𝑋 represents the full training data.\n",
    "\n",
    "#### **Q. Now that we have understood Dropout and BN, where should we add it to our model?**\n",
    "\n",
    "- Emperically it has been found out that dropout works best when it is placed in-between Dense layers of an architecture with a probability of 0.5.\n",
    "- Sometimes adding dropout layers after MaxPooling Layer with lower probability (0.1 to 0.25) also enhances performance.\n",
    "- These are not hard-set rules, rather standard practices which people tend to follow.\n",
    "\n",
    "- As for BatchNorm, the original paper suggested to add BN layer just after Conv Layer and before non-linearity, but later-on it was experimentally found out that placing BN layers after non-linear layers worked better. \n",
    "\n",
    "- Other reasoning for placing BN after both Conv and non-linear layers like ReLU comes from Statistics. If we normalize the feature distribution right after Conv Layer and pass it to the ReLU block, it will clamp the negative values from BN output to 0, effectively changing the distribution itself and defeating the purpose of normalization.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iC-4mkFjydHD"
   },
   "outputs": [],
   "source": [
    "def arch_2(height=128, width=128):\n",
    "    num_classes = 10\n",
    "    hidden_size = 256\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        name=\"model_cnn_2\",\n",
    "        layers=[\n",
    "            layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", input_shape=(height, width, 3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=32, kernel_size=3, padding=\"same\"),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=64, kernel_size=3, padding=\"same\"),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=128, kernel_size=3, padding=\"same\"),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=256, kernel_size=3, padding=\"same\"),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            # layers.MaxPooling2D(),\n",
    "            # layers.Flatten(),\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(units=hidden_size),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(units=num_classes, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cRJ929PHydHD",
    "outputId": "bd384df5-81e0-482b-955b-c902bd77a3f0"
   },
   "outputs": [],
   "source": [
    "model = arch_2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ynt1E4MKydHD",
    "outputId": "90c5fbca-d408-4328-9433-ff4b7c70fc75"
   },
   "outputs": [],
   "source": [
    "model_fit = compile_train_v1(model, train_ds, val_ds, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m2vbOWZRydHD",
    "outputId": "16b085dd-295a-4b63-c7ce-a0c494ef759c"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghLa4EavydHD"
   },
   "source": [
    "**WAIT, WAIT..SOMETHING AIN'T RIGHT HERE...**   \n",
    "\n",
    "We see the training is not very stable here (too many fluctuations)! This was \"kinda\" expected since we added more chaos to the training process, for example \"dropout\" switches off 20% of connections randomly at every step. \n",
    "\n",
    "\n",
    "*Note: Every regularization technique induces some form of chaos to the training process.*  \n",
    "\n",
    "#### Q.**How to solve this issue?**\n",
    "\n",
    "**Rule of Thumb:** Fluctuating (heartbeat) plots imply that the learning rate is too high.  \n",
    "\n",
    "So, we can try tuning it. Or a better alternative is to use a Learning Rate Scheduler and let the model train until the loss/accuracy curve flattens out (also called Early Stopping). \n",
    "\n",
    "In Keras, we can simply add both LR Scheduler and Early Stopping as a callback to `model.fit`.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "# **Quiz 1:** Batch Normalization is helpful in overfitting because :\n",
    "\t\n",
    "a) It normalizes all inputs before sending it to the next layer<br>\n",
    "b) It returns back the normalized mean and standard deviation of weights<br>\n",
    "c) It is a very efficient backpropagation technique<br>\n",
    "d) None of the above<br>\n",
    "\n",
    "Ans : a)\n",
    "\n",
    "Batch normalization is a process to make neural networks faster and more stable through adding extra layers in a deep neural network. The new layer performs the normalizing operation on the input of a layer coming from a previous layer.\n",
    "It works as a regularization technique by adding some noise to the data and thus also prevents overfitting\n",
    "\n",
    "<br><br>\n",
    "\n",
    "### **Modification #3** \n",
    "\n",
    "#### 1. Use `ReduceLROnPlateau` as LR Scheduler and `EarlyStopping` to stop training once the loss curve plateaus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7CFb27iydHD"
   },
   "outputs": [],
   "source": [
    "def compile_train_v2(model, train_ds, val_ds, epochs=10, ckpt_path=\"/tmp/checkpoint\"):\n",
    "    callbacks = [\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.3, patience=5, min_lr=0.00001\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(ckpt_path, save_weights_only=True, monitor='val_accuracy', mode='max', save_best_only=True),\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=10, min_delta=0.001, mode='min'\n",
    "        )\n",
    "    ]\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model_fit = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "    return model_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0IYyAYxydHD",
    "outputId": "5af4146b-2361-48d1-8880-a28aa9c7f616"
   },
   "outputs": [],
   "source": [
    "model = arch_2()\n",
    "model_fit = compile_train_v2(model, train_ds, val_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmZWf-oTydHD",
    "outputId": "caa4f7bf-50dc-4135-bf56-0e376322d759"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PAlNGuGydHE",
    "outputId": "f8f12351-f3e7-45ce-974c-9784cda8a86b"
   },
   "outputs": [],
   "source": [
    "print_accuracy_stats(model, test_ds, class_names)\n",
    "plot_confusion_matrix(model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAlV464dydHE"
   },
   "source": [
    "**Nice Improvements!**\n",
    "\n",
    "Before moving on, let's also study the effect of adding L1/L2 Regularizer to loss functions.   \n",
    "- L2 regularization reduces the impact of insignificant features, thereby, giving a generalizable model. L1 regularization removes some of the features from the model to reduce overfitting.\n",
    "- In `Keras`, we add regularizers in the model definition itself.\n",
    "\n",
    "#### Q. **What is L1 Regularization ?** \n",
    "L1 regularization, also known as L1 norm, combats overfitting by shrinking the parameters towards 0, hence making some features obsolete\n",
    "\n",
    "- L1 Regularization can be interpreted as a form of feature selection\n",
    "- Because when we assign a feature weight = 0, we remove the significance of the feature\n",
    "-  If the input features of our model have weights closer to 0, our L1 norm would be sparse. \n",
    "- A selection of the input features would have weights equal to zero, and the rest would be non-zero. \n",
    "\n",
    "To understand L1 Regularization better, lets take an example : <br>\n",
    "Supoose we want to estimate car prices using machine learning, using the features :\n",
    "- Brand\n",
    "- Engine power\n",
    "- Fuel capacity\n",
    "- Year of manufacturing\n",
    "- Cabin volume\n",
    "\n",
    "When predicting the price of a car, different features will have difference infleunce on the price. For example, it is likely that Fuel capacity of car has a lower influence on the price of a car than Engine power.\n",
    "\n",
    "\n",
    "So our L1 Regularization technique would assign Fuel capacity feature with a zero weight, because it does not have significant effect on the price. We can expect Engine power and other infuential features on the car price to be assigned non-zero weights.\n",
    "\n",
    "Mathematically L1 Regularization can be represented as :\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=10kKlUkyr849jz9bzz_5Wcb55DvK1mvKc' height=200>\n",
    "\n",
    "Essentially, when we use L1 regularization, we are penalizing the absolute value of the weights. \n",
    "\n",
    "L1 Regularizaiton would produce a model that is highly generalized, and only uses a subset of input features, thus reducing the complexity of the model, thus reducing overfitting. \n",
    "\n",
    "#### Q. **What is L2 Regularization ?** \n",
    "\n",
    "- L2 Regularizaiton or L2 norm, counters overfitting by forcing weights to be small, but not making them exactly 0.\n",
    "\n",
    "- So if we are predicting car prices again, this means that less significant features for predicting the car prices would still have some influence over the final prediction, but it would only be a small influence. \n",
    "\n",
    "The regularization term that we add to the loss function when performing L2 regularization is the sum of squares of all of the feature weights:\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1Be9BvuJDV6gzO8PJtwZjMz3blG6pLczd' height=70>\n",
    "\n",
    "\n",
    "So, L2 regularization returns a non-sparse solution since the weights will be non-zero (although some may be close to 0).\n",
    "\n",
    "\n",
    "### **Modification #4** \n",
    "#### 1. Add L2 regularization to `Conv2D` and `Dense` layers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8Ql_xmrydHE"
   },
   "outputs": [],
   "source": [
    "def arch_3(height=128, width=128):\n",
    "    num_classes = 10\n",
    "    hidden_size = 256\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        name=\"model_cnn_3\",\n",
    "        layers=[\n",
    "            layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", input_shape=(height, width, 3),\n",
    "                            kernel_regularizer=regularizers.l2(1e-3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=32, kernel_size=3, padding=\"same\",\n",
    "                            kernel_regularizer=regularizers.l2(1e-3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=64, kernel_size=3, padding=\"same\",\n",
    "                            kernel_regularizer=regularizers.l2(1e-3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=128, kernel_size=3, padding=\"same\",\n",
    "                            kernel_regularizer=regularizers.l2(1e-3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(filters=256, kernel_size=3, padding=\"same\",\n",
    "                            kernel_regularizer=regularizers.l2(1e-3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            # layers.MaxPooling2D(),\n",
    "            # layers.Flatten(),\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "            layers.Dense(units=hidden_size, kernel_regularizer=regularizers.l2(1e-3)),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(units=num_classes, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nA6PlE6ydHE",
    "outputId": "ec7a92c0-86b3-495b-8879-bb16c2392ff2"
   },
   "outputs": [],
   "source": [
    "model = arch_3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QNxeKvTaydHE",
    "outputId": "82cd3630-dad9-423f-b647-f985875bd3a0"
   },
   "outputs": [],
   "source": [
    "model_fit = compile_train_v2(model, train_ds, val_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "txYdig6LydHE",
    "outputId": "bd784928-ba00-4f39-a0e9-26af332d8277"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mBGssPetydHE",
    "outputId": "7f5658e2-4d95-4543-97b0-240d2561695c"
   },
   "outputs": [],
   "source": [
    "print_accuracy_stats(model, test_ds, class_names)\n",
    "plot_confusion_matrix(model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VPuqFDBydHE"
   },
   "source": [
    "**Well, we can see that after adding regularization, the test accruacy improved by quite a bit!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bjTMsHtV4Qv"
   },
   "source": [
    "# **Quiz 2 :** Which of these is true ?\n",
    "\n",
    "L1 and L2 regularization are techniques to reduce the model complexity and prevent overfitting.\n",
    "L2 regression shrinks the coefficients\n",
    "L1 regression not only helps in reducing overfitting but it can help us in feature selection\n",
    "All of the above\n",
    "\n",
    "Ans : d)\n",
    "\n",
    "By adding regularization terms, the value of weights reduces by assuming that a neural network having less weights makes simpler models. And hence, it reduces the overfitting to a certain level.<br>\n",
    "L1 regularization, also known as L1 norm or Lasso (in regression problems), combats overfitting by shrinking the parameters towards 0. This makes some features obsolete. It’s a form of feature selection, because when we assign a feature with a 0 weight, we’re multiplying the feature values by 0 which returns 0, eradicating the significance of that feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EbLgXdaydHE"
   },
   "source": [
    "## **2.** Modifications in Data Pipeline (Data Augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5IjrlpPydHE"
   },
   "source": [
    "#### What is Augmentation?\n",
    "\n",
    "- Augmentation is a technique to `artificially increase` the amount of data by generating new data points from `existing data`. \n",
    "\n",
    "**How can we increase the data from existing data?**  \n",
    "\n",
    "- By making Minor changes such as `flips, translations,brigntness,coloring, rotations etc`. \n",
    "\n",
    "<img src='https://drive.google.com/uc?id=15SJ7_ImxN3Ouzdx6T921JtFg0mS0P_Z4' height=200>\n",
    "\n",
    "\n",
    "\n",
    "**How does it help with training?**  \n",
    "\n",
    "- This leads to greater diversity of data samples being seen by the network hence decreasing the likelihood of overfitting the model on the training dataset. \n",
    "\n",
    "- Also it helps in reducing some of the spurious characteristics of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmPXTHsqydHE"
   },
   "source": [
    "#### What different sort of Augmentation strategies we can apply?\n",
    "\n",
    "Some most common data augmentations are:\n",
    "* padding\n",
    "* random rotating\n",
    "* re-scaling,\n",
    "* vertical and horizontal flipping\n",
    "* translation ( image is moved along X, Y direction)\n",
    "* cropping\n",
    "* zooming\n",
    "* darkening & brightening/color modification\n",
    "* grayscaling\n",
    "* changing contrast\n",
    "* adding noise\n",
    "* random erasing\n",
    "\n",
    "We will discuss some of them in detail here, along with their code in `Keras`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDIe5CinydHE"
   },
   "source": [
    "#### How do we apply augmentation in `tensorflow` / `keras`?\n",
    "\n",
    "There are many ways to apply augmentation in Tensorflow/Keras, few of them are discussed here:\n",
    "1. using the Keras Preprocessing Layers, just like preprocessing functions like `resizing` and `rescaling`, keras also provides data augmentation layers like `tf.keras.layers.RandomFlip`,  `tf.keras.layers.RandomRotation`, etc. These can be used in a similar way as we used the preprocessing functions.\n",
    "2. using tf.image methods like `tf.image.stateless_random_flip_up_down`, `tf.image.stateless_random_brightness`\n",
    "3. using Keras ImageDataGenerator API - It provides quick, out-of-the-box suite of augmentation techniques like standardization, rotation, shifts, flips, brightness change, and many more. \n",
    "\n",
    "In this module, we will be using mostly option 1. Keras Preprocessing Layers for data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ywwfeO5ydHE"
   },
   "source": [
    "Load Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD8eUxwcydHE"
   },
   "outputs": [],
   "source": [
    "# Functions to Load and Visualize Samples\n",
    "# Load Sample\n",
    "def load_sample(output_size=(300, 300)):\n",
    "    sample = keras.utils.get_file(\n",
    "        \"sample.jpg\", \n",
    "        \"https://t3638486.p.clickup-attachments.com/t3638486/a0a4f633-2963-4e06-acae-2ad1d12eba3e/sample.jpg\",\n",
    "    )\n",
    "    sample = keras.utils.load_img(sample, target_size=output_size)\n",
    "    sample = keras.utils.img_to_array(sample)\n",
    "    return sample\n",
    "\n",
    "# Visualize Sample\n",
    "def show_images(imgs, num_rows, num_cols, scale=2):\n",
    "    # show augmented images in a grid layout \n",
    "    aspect_ratio = imgs[0].shape[0]/imgs[0].shape[1]\n",
    "    figsize = (num_cols * scale, num_rows * scale * aspect_ratio)\n",
    "    _, axes = plt.subplots(num_rows, num_cols, figsize=figsize)\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            if num_rows != 1:\n",
    "                axes[i][j].imshow(imgs[i * num_cols + j].numpy().astype(\"uint8\"))\n",
    "                axes[i][j].axes.get_xaxis().set_visible(False)\n",
    "                axes[i][j].axes.get_yaxis().set_visible(False)\n",
    "            else:\n",
    "                plt.imsave('test.png', imgs[i * num_cols + j].numpy()[0].astype(\"uint8\"))\n",
    "                # print(imgs[i * num_cols + j].numpy()[0].astype(\"uint8\"))\n",
    "                axes[j].imshow(imgs[i * num_cols + j].numpy().astype(\"uint8\"))\n",
    "                axes[j].axes.get_xaxis().set_visible(False)\n",
    "                axes[j].axes.get_yaxis().set_visible(False)\n",
    "    plt.subplots_adjust(hspace=0.1, wspace=0)\n",
    "    return axes\n",
    "\n",
    "def apply(img, aug, num_rows=1, num_cols=4, scale=3):\n",
    "    # apply augmentation multiple times to obtain different samples\n",
    "    Y = [aug(img) for _ in range(num_rows * num_cols)]\n",
    "    show_images(Y, num_rows, num_cols, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be0lqesrydHE"
   },
   "source": [
    "#### Basic Augmentation Techniques using `tf.keras.layers.*` and `tf.image`\n",
    "\n",
    "All these augmentation techniques will only apply if the mode is set to `training`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f509qnptydHE"
   },
   "outputs": [],
   "source": [
    "# Required to reset the mode to training! \n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO_HcbjjydHE"
   },
   "source": [
    "a. `RandomCrop`\n",
    "\n",
    "During training, this layer will randomly choose a location to crop images down to a target size. The layer will crop all the images in the same batch to the same cropping location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3F4NY24nydHE",
    "outputId": "b53ea282-63e7-461a-fdf7-e5dd0bfb5be8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RandomCrop\n",
    "\n",
    "sample = load_sample(output_size=(300, 300))\n",
    "aug_layer = RandomCrop(\n",
    "    height = 224,\n",
    "    width = 224,\n",
    ")\n",
    "\n",
    "apply(sample, aug_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtXn-O6PVJE1"
   },
   "outputs": [],
   "source": [
    "# Alternative Implementation using tf.image\n",
    "random_crop = tf.image.random_crop(value=sample, size=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZZRBmQXydHE"
   },
   "source": [
    "b. `RandomTranslation` \n",
    "\n",
    "This layer will apply random translations to each image during training, filling empty space according to `fill_mode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8H1NBfwydHF",
    "outputId": "18165199-014a-484c-a0c9-f1454081dec1"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RandomTranslation\n",
    "\n",
    "sample = load_sample(output_size=(300, 300))\n",
    "aug_layer = RandomTranslation(\n",
    "    height_factor = (-0.2, 0.3),\n",
    "    width_factor = (-0.2, 0.3),\n",
    ")\n",
    "\n",
    "apply(sample, aug_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "sxcX-cxTV1Di"
   },
   "outputs": [],
   "source": [
    "# Alternative Implementation using tf.image\n",
    "random_shift = tf.keras.preprocessing.image.random_shift(sample, hrg = 0.2, wrg = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WrE8WjlcydHF"
   },
   "source": [
    "c. `RandomRotation`\n",
    "\n",
    "This layer will apply random rotations to each image, filling empty space according to fill_mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "4nT-z9-bydHF",
    "outputId": "05559793-84b1-4b97-c59d-287da387d5f2"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RandomRotation\n",
    "\n",
    "sample = load_sample(output_size=(300, 300))\n",
    "aug_layer = RandomRotation(\n",
    "    factor = (-0.2, 0.3),\n",
    ")\n",
    "\n",
    "apply(sample, aug_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnGplpWMWDG4"
   },
   "outputs": [],
   "source": [
    "# Alternative Implementation using tf.image\n",
    "random_rotation = tf.keras.preprocessing.image.random_rotation(sample, rg=500, channel_axis = 2, row_axis=0, col_axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t55SW3RpydHF"
   },
   "source": [
    "d. `RandomFlip`  \n",
    "\n",
    "This layer will flip the images horizontally and or vertically based on the mode attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "gg7qdNdNydHF",
    "outputId": "9b508c0e-1f35-4f54-90d0-2cb0494a7af9"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RandomFlip\n",
    "\n",
    "sample = load_sample(output_size=(300, 300))\n",
    "aug_layer = RandomFlip()\n",
    "\n",
    "apply(sample, aug_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up2qmveZWKfd"
   },
   "outputs": [],
   "source": [
    "# Alternative Implementation using tf.image\n",
    "randomflip = tf.image.random_flip_left_right(sample, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrrOKDYoydHF"
   },
   "source": [
    "e. `RandomBrightness`\n",
    "\n",
    "This layer will randomly increase/reduce the brightness for the input RGB images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "RQwF4WmbydHF",
    "outputId": "80d2b95a-e96c-4f0f-9300-7297b75ed512"
   },
   "outputs": [],
   "source": [
    "sample = load_sample(output_size=(300, 300))\n",
    "\n",
    "try:\n",
    "    from tensorflow.keras.layers import RandomBrightness\n",
    "    aug_layer = RandomBrightness(factor=(-0.2, 0.5))\n",
    "except ImportError:\n",
    "    print(\"This Version of tensorflow doesn't have tensorflow.keras.layers.RandomBrightness class, using tf.image.random_brightness instead\")\n",
    "    aug_layer = lambda x: tf.image.random_brightness(x, 100)\n",
    "apply(sample, aug_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTXqYiBgWUkb"
   },
   "outputs": [],
   "source": [
    "# Alternative Implementation using tf.image\n",
    "random_bright = tf.image.random_brightness(sample, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krcKcUBjydHF"
   },
   "source": [
    "f. `RandomContrast`\n",
    "\n",
    "This layer will randomly adjust the contrast of an image or images by a random factor. Contrast is adjusted independently for each channel of each image during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "yiREXCjbydHF",
    "outputId": "f6244cb5-29da-4811-9d1f-927a7404d1e3"
   },
   "outputs": [],
   "source": [
    "from keras.layers import RandomContrast\n",
    "\n",
    "sample = load_sample(output_size=(300, 300))\n",
    "aug_layer = RandomContrast(factor=(0.5, 0.9))\n",
    "\n",
    "apply(sample, aug_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgx2dX3mlzZT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9h3sNcCTWdlZ"
   },
   "outputs": [],
   "source": [
    "# Alternative Implementation using tf.image\n",
    "random_contrast = tf.image.random_contrast(sample, 0.5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcm7JTjdSmMN"
   },
   "source": [
    "\n",
    "# **Quiz 3:** What are the advantages of data augmentation ?\n",
    "\n",
    "a) It prevents underfitting.<br>\n",
    "b) It is used to expand the dataset by variations and helps in developing a more generalized model<br>\n",
    "c) Both a) and b)<br>\n",
    "d) None of the above<br>\n",
    "\n",
    "Ans : b)\n",
    "\n",
    "Solution :\n",
    "\n",
    "Data augmentation is useful to improve performance and outcomes of machine learning models by forming new and different examples to train datasets. If the dataset in a machine learning model is rich and sufficient, the model performs better and more accurately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buL_2t6eydHF"
   },
   "source": [
    "Now let's apply some of the augmentation techniques on the clothing-dataset!\n",
    "\n",
    "### Modification #5: Apply Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8o6FcWBydHF"
   },
   "outputs": [],
   "source": [
    "def preprocess_v2(train_data, val_data, test_data, target_height=128, target_width=128):\n",
    "\n",
    "    # Data Processing Stage with resizing and rescaling operations #same as before for test,val\n",
    "    data_preprocess = keras.Sequential(\n",
    "        name=\"data_preprocess\",\n",
    "        layers=[\n",
    "            layers.Resizing(target_height, target_width),\n",
    "            layers.Rescaling(1.0/255),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Data Processing Stage with resizing and rescaling operations\n",
    "    data_augmentation = keras.Sequential(\n",
    "        name=\"data_augmentation\",\n",
    "        layers=[\n",
    "            layers.Resizing(156, 156), # First resize to 156,156\n",
    "            layers.RandomCrop(target_height, target_width), # Then randomly crop 128,128 region\n",
    "            # layers.RandomBrightness(0.2), # Modify brightness by 0.2 factor\n",
    "            layers.Rescaling(1.0/255), # Finally rescale\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Perform Data Processing on the train, val, test dataset\n",
    "    train_ds = train_data.map(\n",
    "        lambda x, y: (data_augmentation(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_data.map(\n",
    "        lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = test_data.map(\n",
    "        lambda x, y: (data_preprocess(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    ).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAJ0Ah4QydHF"
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = preprocess_v2(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5Jt1M4AydHF",
    "outputId": "f4a695b5-3ff2-4a41-c435-76f99eea2ad1"
   },
   "outputs": [],
   "source": [
    "model = arch_3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPU-LRP4ydHF",
    "outputId": "b1590fbd-737c-484e-9896-94448b412acf"
   },
   "outputs": [],
   "source": [
    "model_fit = compile_train_v2(model, train_ds, val_ds, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "3huhN22CydHF",
    "outputId": "153d93ed-586b-42b1-b1a4-b162be7faf7a"
   },
   "outputs": [],
   "source": [
    "plot_accuracy(model_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "id": "-4T0v15RydHF",
    "outputId": "a7dedd44-2c86-437f-be93-efe48b78acfc"
   },
   "outputs": [],
   "source": [
    "print_accuracy_stats(model, test_ds, class_names)\n",
    "plot_confusion_matrix(model, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WdxxSS0ydHF"
   },
   "source": [
    "**>80% Val Accuracy**  \n",
    "\n",
    "For the first time ever, we were able to breach 80% val accuracy barrier and also obtained highest ever test accuracy, which shows that Data Augmentation helps.\n",
    "\n",
    "#### But does Data Augmentation always improve the performance of the model?\n",
    "* The main idea **how Augmentation works is** `it improve model Performance when we have less data.`\n",
    "* By increasing the amount of Data.\n",
    "* So, that our **model can generalize better**.\n",
    "* **But Data Augmentation improves result till a particular point only.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVkqZLXZY26m"
   },
   "source": [
    "# **Quiz 4:** Which of the following statements is true ?\n",
    "\t\n",
    "a) Shallow neural networks have only one hidden layer<br>\n",
    "b) Ridge regression is an example of L1 regularization<br>\n",
    "c) Max Pooling layer doesn’t have any trainable parameters<br>\n",
    "d) All of the above<br>\n",
    "\n",
    "Ans : a), c)\n",
    "\n",
    "Shallow neural networks have only one hidden layer, in contrast to deep neural networks which have multiple hidden layers.\n",
    "Ridge regression is an example of L2 regularization. \n",
    "\n",
    "Lasso regression is an example of L1 regularization\n",
    "True, Max Pooling layers don't have any trainable parameters. \n",
    "\n",
    "In the forward pass, it passes the maximum value within each rectangle to the next layer. \n",
    "In the backward pass, it propagates error in the next layer to the place where the max value is taken.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTDKPMaKYYz0"
   },
   "source": [
    "# Summary : \n",
    "\n",
    "In this lecture, we covered:\n",
    "\n",
    "- How to Code Convolution and Max Pooling layers from scratch!\n",
    "- Batch Normalization\n",
    "- Dropout\n",
    "- L1 and L2 Regularization\n",
    "- Data Augmentation Techniques\n",
    "\n",
    "In the next class, we will discuss about forward and backward propagation in CNN components."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "oa9RuSjWydHB",
    "F0vK_FgUydHC",
    "jabdLtygydHC",
    "Oz4OcQJXydHC",
    "mwxS-UgYydHD",
    "6BOlAYFXydHD",
    "ghLa4EavydHD",
    "YAlV464dydHE",
    "S5IjrlpPydHE",
    "jmPXTHsqydHE",
    "dDIe5CinydHE",
    "5WdxxSS0ydHF"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "68805b7def6463cb34663ee90d9d99d70cc395bf086608cbfac241e62146374f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
